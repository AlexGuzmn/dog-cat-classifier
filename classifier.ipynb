{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DogCatClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import image\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set model up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convolution parameters**\n",
    "- ```filters```: no. of convolution output layers, using [32, 64, 128] as advised by Rosenbrock (2018)\n",
    "- ```kernel_size=3```: convolution matrix of size 3x3\n",
    "- ```padding=\"valid\"```: no padding is added\n",
    "- ```activation=None```: raw value is used\n",
    "**Pooling layers**\n",
    "- Maximum pooling picks up features when background is darker than subject\n",
    "- Minimum pooling picks up features when background is lighter than subject\n",
    "- Average pooling smooths out image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=3, padding=\"valid\", activation=\"relu\", input_shape=(100, 100, 1)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=64, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=128, kernel_size=3, padding=\"valid\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dense(2, activation=\"sigmoid\"))\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=[tf.keras.metrics.BinaryAccuracy(),\n",
    "                       tf.keras.metrics.FalseNegatives()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_tensor(path):\n",
    "    img = image.load_img(path, target_size=(100, 100))\n",
    "    tensor = np.expand_dims(img, axis=0)\n",
    "    return np.mean(tensor, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_tensors(paths):\n",
    "    return np.vstack([img_tensor(path) for path in paths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths = list()\n",
    "train_dog_len = 0\n",
    "train_cat_len = 0\n",
    "with open(\"training/dog/dogs.txt\", \"r\") as file:\n",
    "    for line in file:\n",
    "        train_dog_len += 1\n",
    "        train_paths.append(\"training/dog/\" + line[0:-1])\n",
    "with open(\"training/cat/cats.txt\", \"r\") as file:\n",
    "    for line in file:\n",
    "        train_cat_len += 1\n",
    "        train_paths.append(\"training/cat/\" + line[0:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = img_tensors(train_paths)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_tmp = list()\n",
    "for i in range(train_dog_len): y_train_tmp.append(0)\n",
    "for i in range(train_cat_len): y_train_tmp.append(1)\n",
    "y_train = tf.keras.utils.to_categorical(np.array(y_train_tmp), num_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=20, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Must be tensors from testing subset\n",
    "x_test = None\n",
    "y_test = None\n",
    "model.evaluate(x_test, y_test, batch_size=64)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1727fa48dc9b396b58f99ce2cd2ac2358e549049d7d24b4bfd1edfa6ec7e7320"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('.env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
